{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53fb561-1736-4bda-9524-8a4b72bb6797",
   "metadata": {},
   "source": [
    "# SOAP Note LLM Judge Comparison\n",
    "\n",
    "This notebook demonstrates how to compare different LLMs used as judges and log the results to the Sagemaker-managed MLflow tracking server. It shows how to load the data, define a model that generates the SOAP notes, compose a set of LLM-as-a-Judge metrics, and define a judge models themselves.  \n",
    "In order to run this notebook, make sure that the appropriate MLflow tracking server is running inside the Sagemaker Studio.\n",
    "\n",
    "You can set the tracking server by name using the `set_sagemaker_tracking_server()` helper function. Next, specify the active experiment. The `set_experiment()` function creates the experiment with the provided name, if it does not exist yet.  \n",
    "It is also recommended to use [tags](https://mlflow.org/docs/latest/getting-started/logging-first-model/step3-create-experiment#notes-on-tags-vs-experiments), which allow to filter the experiments. Every prompt engineering workflow must set a `task` tag to `prompt-engineering` and specify the descriptive project name in the `project` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d6123b3-4739-4d55-a9b8-5cc4d82a5dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/soap-notes/lib/python3.12/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from utils.aws import (\n",
    "    SAGEMAKER_DEFAULT_BUCKET,\n",
    "    bedrock_runtime_client,\n",
    "    sagemaker_session,\n",
    ")\n",
    "from utils.bedrock import BedrockModel\n",
    "from utils.evaluation import compare_judge_models\n",
    "from utils._mlflow import set_experiment, set_sagemaker_tracking_server\n",
    "from utils.metrics.soap_note import completeness, source_grounding\n",
    "from utils.prompts.soap_note import format_soap_note\n",
    "\n",
    "\n",
    "DATA_DIR = \"dataset\"\n",
    "\n",
    "set_sagemaker_tracking_server(\"a360-mlflow-tracking-server\")\n",
    "mlflow_experiment_name = \"SOAP Note LLM-Judge Comparison\"\n",
    "mlflow_experiment_tags = {\n",
    "    \"task\": \"prompt-engineering\",\n",
    "    \"project\": \"soap-note-generation\",\n",
    "    \"mlflow.note.content\": \"This experiment compares different LLM judges for SOAP note evaluation\",\n",
    "}\n",
    "experiment = set_experiment(mlflow_experiment_name, mlflow_experiment_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a90fc-4180-49a5-bc87-ef7807d325be",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "See the `01-Data Pre-Processing.ipynb` notebook for instructions on how to prepare the data to be in compatible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6aeae96-8c4f-40bf-b634-26b349e662ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, Ava. I'm Doctor. Bennett. It's great to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. I'm Doctor. Chen. You must be Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, Ms. Cooper. I'm Doctor. Bennett....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, Jasmine. How have you been? Look, doc. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello, I'm Doctor. Patterson. You must be Jenn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Good morning. I'm Doctor. Chin. You must be Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hello Mia, I'm Doctor. Harrison. Please come i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Good morning, Mrs. Parker. I'm Doctor. Roberts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Morning Ms. Davis, I'm Doctor. Warren. What br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good morning Ms. Wright. How are you today? Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hello, I'm Doctor. Bennett. You must be Patric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Good morning I'm Doctor Adams you must be Robe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hello, I'm Doctor. Roberts. You must be Sarah?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Good morning. You must be Sarah. I'm Doctor. E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Good morning. I'm doctor. Chin. You must be So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>So sorry I'm late, Dr. Hendon. Traffic was ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Good afternoon! I'm Dr. Paul Ruff. It's a plea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Good morning! I'm Dr. Johnson, it's a pleasure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I am so, so sorry I'm late, Dr. Mason! The tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           transcript\n",
       "0   Hi, Ava. I'm Doctor. Bennett. It's great to me...\n",
       "1   Good morning. I'm Doctor. Chen. You must be Da...\n",
       "2   Good morning, Ms. Cooper. I'm Doctor. Bennett....\n",
       "3   Hello, Jasmine. How have you been? Look, doc. ...\n",
       "4   Hello, I'm Doctor. Patterson. You must be Jenn...\n",
       "5   Good morning. I'm Doctor. Chin. You must be Ka...\n",
       "6   Hello Mia, I'm Doctor. Harrison. Please come i...\n",
       "7   Good morning, Mrs. Parker. I'm Doctor. Roberts...\n",
       "8   Morning Ms. Davis, I'm Doctor. Warren. What br...\n",
       "9   Good morning Ms. Wright. How are you today? Gr...\n",
       "10  Hello, I'm Doctor. Bennett. You must be Patric...\n",
       "11  Good morning I'm Doctor Adams you must be Robe...\n",
       "12  Hello, I'm Doctor. Roberts. You must be Sarah?...\n",
       "13  Good morning. You must be Sarah. I'm Doctor. E...\n",
       "14  Good morning. I'm doctor. Chin. You must be So...\n",
       "15  So sorry I'm late, Dr. Hendon. Traffic was ter...\n",
       "16  Good afternoon! I'm Dr. Paul Ruff. It's a plea...\n",
       "17  Good morning! I'm Dr. Johnson, it's a pleasure...\n",
       "18  I am so, so sorry I'm late, Dr. Mason! The tra..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation data\n",
    "eval_data_path = os.path.join(DATA_DIR, \"transcripts-plain.csv\")\n",
    "if not os.path.isfile(eval_data_path):\n",
    "    sagemaker_session.download_data(\n",
    "        DATA_DIR,\n",
    "        SAGEMAKER_DEFAULT_BUCKET,\n",
    "        \"prompt-engineering/soap-notes/dataset/transcripts-plain.csv\",\n",
    "    )\n",
    "eval_df = pd.read_csv(eval_data_path)\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcabecd-d10d-49ec-b5e0-dcb52cf2db50",
   "metadata": {},
   "source": [
    "## Model and Prompt Definition\n",
    "\n",
    "Next, we need to define the model and prompt with which the outputs will be generated (SOAP notes in this case).  \n",
    "Since the model will be invoked on each row of the input `DataFrame`, the prompt can specify variables (enclosed in single curly braces), whose names must correspond to column names in the input `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa057048-2011-47a9-bc13-d3ebf6098322",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOAP_NOTE_GENERATION_PROMPT = \"\"\"\\\n",
    "You are tasked with generating a SOAP note based on a transcript of a conversation between a doctor and a patient. A SOAP note is a method of documentation used by healthcare providers that includes four sections: Subjective, Objective, Assessment, and Plan.\n",
    "\n",
    "Here is the transcript of the doctor-patient conversation:\n",
    "\n",
    "<transcript>\n",
    "{transcript}\n",
    "</transcript>\n",
    "\n",
    "Carefully analyze the transcript and extract relevant information for each section of the SOAP note. Follow these guidelines for each section:\n",
    "\n",
    "1. Subjective: Include the patient's chief complaint, history of present illness, and any relevant past medical history, family history, or social history mentioned by the patient.\n",
    "\n",
    "2. Objective: Note any physical examination findings, vital signs, or test results mentioned by the doctor. If specific measurements or results are not provided, leave this section brief or note that information was not available in the transcript.\n",
    "\n",
    "3. Assessment: Summarize the doctor's diagnosis or differential diagnoses based on the subjective and objective information. Include any medical reasoning or thought process expressed by the doctor.\n",
    "\n",
    "4. Plan: List any treatment plans, medications prescribed, further tests ordered, referrals made, or follow-up instructions given by the doctor.\n",
    "\n",
    "Provide your output as a JSON object with four keys: \"subjective\", \"objective\", \"assessment\", and \"plan\". Each key should contain a string value summarizing the relevant information for that section.\"\"\"\n",
    "ASSISTANT_RESPONSE_PREFILL = \"\"\"\\\n",
    "{\n",
    "    \"subjective\": \\\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44333e1-ae66-4e8a-97b9-6f74bf511753",
   "metadata": {},
   "source": [
    "To create the model, you use the `BedrockModel` class. You must provide the Bedrock model ID, and the `bedrock-runtime` `boto3` client. Note that both model ID and [inference profile](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles.html) ID are supported. You should prefer the inference profile whenever possible.  \n",
    "Additionaly, you can provide the `inference_config` and `additional_req_fields` parameters, that correspond to `inferenceConfig` and `additionalmodelRequestFields` parameters of the Bedrock [Converse API](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-call.html) respectively.\n",
    "\n",
    "The `BedrockModel` class exposes a set of useful properties that are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fadbce-2307-4041-98cd-99b7d6fcbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haiku.id='us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
      "haiku.info={'modelArn': 'arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0', 'modelId': 'anthropic.claude-3-5-haiku-20241022-v1:0', 'modelName': 'Claude 3.5 Haiku', 'providerName': 'Anthropic', 'inputModalities': ['TEXT', 'IMAGE'], 'outputModalities': ['TEXT'], 'responseStreamingSupported': True, 'customizationsSupported': [], 'inferenceTypesSupported': ['INFERENCE_PROFILE'], 'modelLifecycle': {'status': 'ACTIVE'}}\n",
      "haiku.name='claude-3.5-haiku'\n",
      "haiku.inf_config={'temperature': 0.0}\n",
      "haiku.is_reasoner=False\n"
     ]
    }
   ],
   "source": [
    "haiku = BedrockModel(\n",
    "    \"us.anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "    bedrock_runtime_client,\n",
    "    inf_config={\"temperature\": 0.0},\n",
    ")\n",
    "print(f\"{haiku.id=}\")\n",
    "print(f\"{haiku.info=}\")\n",
    "print(f\"{haiku.name=}\")\n",
    "print(f\"{haiku.inf_config=}\")\n",
    "print(f\"{haiku.is_reasoner=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc056da-b754-4c40-a8b6-0dad19693950",
   "metadata": {},
   "source": [
    "Next, you need to create an *evaluation function*. This is the function that MLflow will invoke with the input `DataFrame`. It is responsible for invoking the model on each row of this `DataFrame` and returning another `DataFrame` with all the information required to calculate the metrics.\n",
    "\n",
    "The `BedrockModel` automates all of that by providing the `make_eval_fn()` helper method. Aside from the prompt, you can optionally specify the prefill message for the LLM (useful for generating JSON data) and a `custom_cols` parameter. This must be a dictionary that maps custom column names in the output `DataFrame` to a function that will be invoked with the raw Converse API response and return something that can be stored in the `DataFrame`, so you can use it to augment the output `DataFrame` with whatever you want.  \n",
    "In the example below, `custom_cols` specifies the `soap_note` column and a `format_soap_note` function. This function transforms the JSON-formatted SOAP note output by an LLM into a plaintext, which later on will be passed to the Judge LLM.\n",
    "\n",
    "`make_eval_fn()` also captures token usage and response latencies that can also be logged to MLflow as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89e5d19-f809-44bd-8947-05b76448dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_COL_NAME = \"soap_note\"\n",
    "haiku_eval_fn = haiku.make_eval_fn(\n",
    "    SOAP_NOTE_GENERATION_PROMPT,\n",
    "    ASSISTANT_RESPONSE_PREFILL,\n",
    "    custom_cols={PRED_COL_NAME: format_soap_note},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e994c5-0d91-4a25-a5dd-62dc402f201b",
   "metadata": {},
   "source": [
    "## LLM Judge and Metrics Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29edda-bb80-4419-8c83-fd25ac5b3d64",
   "metadata": {},
   "source": [
    "LLM judges are simply defined as other `BedrockModel` instances. This example also shows how to define `BedrockModel`'s with reasoning capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a892cd1a-174e-4062-850e-6108728e2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_config = {\"temperature\": 0.0}\n",
    "sonnet = BedrockModel(\n",
    "    \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    bedrock_runtime_client,\n",
    "    inf_config=inf_config,\n",
    ")\n",
    "sonnet_thinking = BedrockModel(\n",
    "    \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    bedrock_runtime_client,\n",
    "    \"claude-3.7-sonnet-thinking\",\n",
    "    # temperature is not supported for Sonnet 3.7 with extended reasoning\n",
    "    {\"maxTokens\": 4096},\n",
    "    {\"thinking\": {\"type\": \"enabled\", \"budget_tokens\": 2048}}\n",
    ")\n",
    "r1 = BedrockModel(\n",
    "    \"us.deepseek.r1-v1:0\", bedrock_runtime_client, inf_config=inf_config\n",
    ")\n",
    "judge_models = [haiku, sonnet, sonnet_thinking, r1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd947ae-eccc-4897-81a3-46b4181f9bab",
   "metadata": {},
   "source": [
    "LLM-as-a-Judge metrics must be defined separately for each task. See the `utils/metrics/soap_note.py` file for an example of how LLM-as-a-Judge metrics can be defined.  \n",
    "To create the metrics, we simply need to provide the list of aggregations we want to use to aggreate the per-row scores.\n",
    "\n",
    "`completeness` metric measures the extent to which the SOAP note captures all the important medical information present in the original transcript.\n",
    "\n",
    "`source_grounding` metric measures the extent to which the SOAP note includes only information that is directly supported by the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b1d85b-bc23-4dc3-b6c0-b7ee7a4d356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = [\"min\", \"max\", \"mean\", \"median\"]\n",
    "judge_metrics = [completeness(aggregations), source_grounding(aggregations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ba56f-f353-449c-88dc-eb040599a6b6",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Finally, to run the comparison of different judges, you call the `compare_judge_models()` function. This function initiates the parent MLflow run, under which it logs nested runs that correspond to evaluations with individual judges.  \n",
    "The function makes sure to generate the predictions only once, and then reuse these predictions across the judges to save the costs and ensure identical evaluation conditions. It also takes care of logging all the metics, judge model parameters and prompts that were used to calculate the metrics.\n",
    "\n",
    "Apart from arguments that were discussed above, you must provide the name of the column in the `DataFrame` returned by the evaluation model which contains the predictions. Values from this column are then used to pass predictions (formatted SOAP notes in our case) to the metrics alongside the input transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27338c52-f366-4c8d-ade8-e78f3101904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/16 12:09:34 INFO mlflow.models.evaluation.utils.trace: Auto tracing is temporarily enabled during the model evaluation for computing some metrics and debugging. To disable tracing, call `mlflow.autolog(disable=True)`.\n",
      "2025/04/16 12:09:34 INFO mlflow.models.evaluation.evaluators.default: Computing model predictions.\n",
      "2025/04/16 12:12:33 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run claude-3.5-haiku at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34/runs/1dd082ddb89241ceb13467d1f3e7c4e5\n",
      "🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1cc0d849bc34819a25ce78e8702eb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/16 12:18:46 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run claude-3.7-sonnet at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34/runs/dda636f743b94f3193242424e66d090b\n",
      "🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/16 12:28:03 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run claude-3.7-sonnet-thinking at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34/runs/9642eeae7ab44a4e95293fae893f52b4\n",
      "🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/16 12:54:35 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run deepseek-r1 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34/runs/3c9023eb026b4f0897e9a5093c56081e\n",
      "🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34\n",
      "🏃 View run claude-3.5-haiku at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34/runs/30b4171901ae4947974e31c3054efba5\n",
      "🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/34\n"
     ]
    }
   ],
   "source": [
    "eval_results = compare_judge_models(\n",
    "    judge_models,\n",
    "    haiku_eval_fn,\n",
    "    eval_df,\n",
    "    judge_metrics,\n",
    "    PRED_COL_NAME,\n",
    "    parent_run_name=haiku.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6e3744-05e3-4083-8bfb-a5e2afa402e0",
   "metadata": {},
   "source": [
    "`compare_judge_models` returns the dictionary that maps child run names to `mlflow.models.EvaluationResult` objects that can be further inspected to see the evaluation results for a particular run.\n",
    "\n",
    "More detailed information can be seen, obviously, in the MLflow UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c50c156f-6ee5-43dd-8e69-03b25dce204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for run claude-3.5-haiku:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ed0d99731d449886aa1671d60ff6aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>outputs</th>\n",
       "      <th>completeness/score</th>\n",
       "      <th>completeness/justification</th>\n",
       "      <th>source_grounding/score</th>\n",
       "      <th>source_grounding/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, Ava. I'm Doctor. Bennett. It's great to me...</td>\n",
       "      <td>Subjective: Patient Ava presents with concern ...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section provides...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. I'm Doctor. Chen. You must be Da...</td>\n",
       "      <td>Subjective: Patient David, a Marine Corps enli...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section captures...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section is mostl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, Ms. Cooper. I'm Doctor. Bennett....</td>\n",
       "      <td>Subjective: Patient Ms. Cooper presents with c...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section captures...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section is mostl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Hi, Ava. I'm Doctor. Bennett. It's great to me...   \n",
       "1  Good morning. I'm Doctor. Chen. You must be Da...   \n",
       "2  Good morning, Ms. Cooper. I'm Doctor. Bennett....   \n",
       "\n",
       "                                             outputs  completeness/score  \\\n",
       "0  Subjective: Patient Ava presents with concern ...                   4   \n",
       "1  Subjective: Patient David, a Marine Corps enli...                   4   \n",
       "2  Subjective: Patient Ms. Cooper presents with c...                   4   \n",
       "\n",
       "                          completeness/justification  source_grounding/score  \\\n",
       "0  ## Subjective\\nThe subjective section provides...                       5   \n",
       "1  ## Subjective\\nThe subjective section captures...                       4   \n",
       "2  ## Subjective\\nThe subjective section captures...                       4   \n",
       "\n",
       "                      source_grounding/justification  \n",
       "0  ## Subjective\\nThe subjective section accurate...  \n",
       "1  ## Subjective\\nThe subjective section is mostl...  \n",
       "2  ## Subjective\\nThe subjective section is mostl...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for run claude-3.7-sonnet:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d95086c4d43400b8fbb9113c3d93066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>outputs</th>\n",
       "      <th>completeness/score</th>\n",
       "      <th>completeness/justification</th>\n",
       "      <th>source_grounding/score</th>\n",
       "      <th>source_grounding/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, Ava. I'm Doctor. Bennett. It's great to me...</td>\n",
       "      <td>Subjective: Patient Ava presents with concern ...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section effectiv...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. I'm Doctor. Chen. You must be Da...</td>\n",
       "      <td>Subjective: Patient David, a Marine Corps enli...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section effectiv...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, Ms. Cooper. I'm Doctor. Bennett....</td>\n",
       "      <td>Subjective: Patient Ms. Cooper presents with c...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section effectiv...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Hi, Ava. I'm Doctor. Bennett. It's great to me...   \n",
       "1  Good morning. I'm Doctor. Chen. You must be Da...   \n",
       "2  Good morning, Ms. Cooper. I'm Doctor. Bennett....   \n",
       "\n",
       "                                             outputs  completeness/score  \\\n",
       "0  Subjective: Patient Ava presents with concern ...                   5   \n",
       "1  Subjective: Patient David, a Marine Corps enli...                   5   \n",
       "2  Subjective: Patient Ms. Cooper presents with c...                   5   \n",
       "\n",
       "                          completeness/justification  source_grounding/score  \\\n",
       "0  ## Subjective\\nThe subjective section effectiv...                       5   \n",
       "1  ## Subjective\\nThe subjective section effectiv...                       5   \n",
       "2  ## Subjective\\nThe subjective section effectiv...                       5   \n",
       "\n",
       "                      source_grounding/justification  \n",
       "0  ## Subjective\\nThe subjective section accurate...  \n",
       "1  ## Subjective\\nThe subjective section accurate...  \n",
       "2  ## Subjective\\nThe subjective section accurate...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for run claude-3.7-sonnet-thinking:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4678fedb3b8a4e678352b80de8c13b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>outputs</th>\n",
       "      <th>completeness/score</th>\n",
       "      <th>completeness/justification</th>\n",
       "      <th>source_grounding/score</th>\n",
       "      <th>source_grounding/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, Ava. I'm Doctor. Bennett. It's great to me...</td>\n",
       "      <td>Subjective: Patient Ava presents with concern ...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section is compr...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. I'm Doctor. Chen. You must be Da...</td>\n",
       "      <td>Subjective: Patient David, a Marine Corps enli...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section is thoro...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section is accur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, Ms. Cooper. I'm Doctor. Bennett....</td>\n",
       "      <td>Subjective: Patient Ms. Cooper presents with c...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe subjective section effectiv...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe subjective section accurate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Hi, Ava. I'm Doctor. Bennett. It's great to me...   \n",
       "1  Good morning. I'm Doctor. Chen. You must be Da...   \n",
       "2  Good morning, Ms. Cooper. I'm Doctor. Bennett....   \n",
       "\n",
       "                                             outputs  completeness/score  \\\n",
       "0  Subjective: Patient Ava presents with concern ...                   4   \n",
       "1  Subjective: Patient David, a Marine Corps enli...                   4   \n",
       "2  Subjective: Patient Ms. Cooper presents with c...                   4   \n",
       "\n",
       "                          completeness/justification  source_grounding/score  \\\n",
       "0  ## Subjective\\nThe subjective section is compr...                       5   \n",
       "1  ## Subjective\\nThe subjective section is thoro...                       4   \n",
       "2  ## Subjective\\nThe subjective section effectiv...                       5   \n",
       "\n",
       "                      source_grounding/justification  \n",
       "0  ## Subjective\\nThe subjective section accurate...  \n",
       "1  ## Subjective\\nThe subjective section is accur...  \n",
       "2  ## Subjective\\nThe subjective section accurate...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for run deepseek-r1:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55266d3b29f24205a1700459a0d97c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>outputs</th>\n",
       "      <th>completeness/score</th>\n",
       "      <th>completeness/justification</th>\n",
       "      <th>source_grounding/score</th>\n",
       "      <th>source_grounding/justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi, Ava. I'm Doctor. Bennett. It's great to me...</td>\n",
       "      <td>Subjective: Patient Ava presents with concern ...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe note effectively captures t...</td>\n",
       "      <td>5</td>\n",
       "      <td>## Subjective\\nThe section accurately captures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning. I'm Doctor. Chen. You must be Da...</td>\n",
       "      <td>Subjective: Patient David, a Marine Corps enli...</td>\n",
       "      <td>3</td>\n",
       "      <td>## Subjective\\nThe note accurately captures Da...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe section accurately captures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning, Ms. Cooper. I'm Doctor. Bennett....</td>\n",
       "      <td>Subjective: Patient Ms. Cooper presents with c...</td>\n",
       "      <td>3</td>\n",
       "      <td>## Subjective\\nThe note appropriately captures...</td>\n",
       "      <td>4</td>\n",
       "      <td>## Subjective\\nThe section accurately captures...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "0  Hi, Ava. I'm Doctor. Bennett. It's great to me...   \n",
       "1  Good morning. I'm Doctor. Chen. You must be Da...   \n",
       "2  Good morning, Ms. Cooper. I'm Doctor. Bennett....   \n",
       "\n",
       "                                             outputs  completeness/score  \\\n",
       "0  Subjective: Patient Ava presents with concern ...                   4   \n",
       "1  Subjective: Patient David, a Marine Corps enli...                   3   \n",
       "2  Subjective: Patient Ms. Cooper presents with c...                   3   \n",
       "\n",
       "                          completeness/justification  source_grounding/score  \\\n",
       "0  ## Subjective\\nThe note effectively captures t...                       5   \n",
       "1  ## Subjective\\nThe note accurately captures Da...                       4   \n",
       "2  ## Subjective\\nThe note appropriately captures...                       4   \n",
       "\n",
       "                      source_grounding/justification  \n",
       "0  ## Subjective\\nThe section accurately captures...  \n",
       "1  ## Subjective\\nThe section accurately captures...  \n",
       "2  ## Subjective\\nThe section accurately captures...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for run_name, result in eval_results.items():\n",
    "    print(f\"Evaluation results for run {run_name}:\")\n",
    "    display(result.tables[\"eval_results_table\"].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "user-env:(py312-soap-notes)",
   "language": "python",
   "name": "soap-notes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
